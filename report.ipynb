{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e194a2",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Video classification is a fundamental problem in computer vision with\n",
    "applications in action recognition, surveillance, sports analytics, and\n",
    "human–computer interaction. The task involves assigning semantic labels to\n",
    "video sequences by analyzing spatial and temporal information present across\n",
    "frames.\n",
    "\n",
    "This assignment presents a comparative study of classical and deep learning\n",
    "approaches for video classification. Classical methods rely on hand-crafted\n",
    "features combined with traditional machine learning algorithms, while modern\n",
    "deep learning approaches learn spatiotemporal representations directly from\n",
    "data.\n",
    "\n",
    "The objective of this work is to analyze the evolution from classical to\n",
    "deep learning–based video classification techniques and to understand the\n",
    "trade-offs in terms of performance, interpretability, and computational cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc56195d",
   "metadata": {},
   "source": [
    "## 2. Dataset Description\n",
    "\n",
    "A subset of the HMDB51 dataset was used for this study. HMDB51 is a widely\n",
    "used benchmark dataset for human action recognition, consisting of videos\n",
    "from diverse real-world scenarios.\n",
    "\n",
    "For this assignment, a binary classification task was formulated using the\n",
    "following action classes:\n",
    "- Walking\n",
    "- Running\n",
    "\n",
    "Each video is represented as a sequence of RGB frames stored in\n",
    "class-specific folders. A reduced subset was chosen to ensure stable training\n",
    "and evaluation under limited computational resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a6fee",
   "metadata": {},
   "source": [
    "## 3. Methodology\n",
    "\n",
    "### 3.1 Classical Video Classification Approach\n",
    "\n",
    "The classical approach follows a traditional video analytics pipeline\n",
    "consisting of feature extraction, feature aggregation, and classification\n",
    "using machine learning algorithms.\n",
    "\n",
    "#### 3.1.1 Feature Extraction\n",
    "\n",
    "Three types of features were extracted from video frames:\n",
    "\n",
    "- **Color Features:** RGB color histograms were computed to capture global\n",
    "  color distribution across frames.\n",
    "- **Texture Features:** Local Binary Pattern (LBP) descriptors were used to\n",
    "  capture texture information from grayscale frames.\n",
    "- **Motion Features:** Frame differencing was applied between consecutive\n",
    "  frames to estimate motion intensity.\n",
    "\n",
    "Frame-level features were aggregated temporally using statistical measures\n",
    "such as mean and standard deviation to form a single video-level feature\n",
    "vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3ba8f",
   "metadata": {},
   "source": [
    "### 3.2 Deep Learning–Based Approach\n",
    "\n",
    "Deep learning approaches were implemented to automatically learn\n",
    "spatiotemporal representations from video data.\n",
    "\n",
    "#### 3.2.1 2D CNN with Temporal Pooling\n",
    "\n",
    "A pre-trained ResNet-18 model was used as a frame-level feature extractor.\n",
    "Features from multiple frames were aggregated using temporal average pooling\n",
    "to obtain a video-level representation. Transfer learning was employed by\n",
    "initializing the model with ImageNet weights.\n",
    "\n",
    "#### 3.2.2 3D Convolutional Neural Network\n",
    "\n",
    "A lightweight 3D CNN was implemented to demonstrate joint spatial and\n",
    "temporal feature learning using 3D convolutions. Due to computational and GPU\n",
    "session constraints, this model was demonstrated architecturally with limited\n",
    "evaluation rather than full-scale training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d0bc1",
   "metadata": {},
   "source": [
    "## 4. Experimental Setup\n",
    "\n",
    "The dataset was split into training and testing sets using an 80:20 ratio.\n",
    "All video sequences were temporally normalized to a fixed number of frames\n",
    "to enable batch processing.\n",
    "\n",
    "For classical methods, features were standardized before training machine\n",
    "learning models including Support Vector Machines, Random Forests, and\n",
    "Logistic Regression.\n",
    "\n",
    "For deep learning models, training was performed using the Adam optimizer\n",
    "and cross-entropy loss. Due to computational constraints, limited epochs\n",
    "were used for training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35253973",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
